#!/usr/bin/env bash

# NAME
#     vw_train_dlm -- run Vowpal Wabbit training of discriminative lexicon model
# 
# SYNOPSIS
#     vw_train_dlm SAMPLE MODEL_OUT
# 
# DESCRIPTION
#     Runs VW training for given data sample with parameters described at
#     
#         https://svn.ms.mff.cuni.cz/trac/mtmarathon-2013/wiki/LexiconMorphologicallyRich#VowpalWabbit
# 
#     Data file can be generated e.g. by extract_features_dlm_baseline.py 
#     script, and should be gzipped. 
#
#     Output model coefficients are written to MODEL_OUT file.
    
TRAIN=$1
MODEL=$2
CACHE=tmp_vwcache_$$

rm -f $MODEL
rm -f $CACHE

zcat $TRAIN \
vw --quadratic st \
   --hash all \
   --noconstant \
   --bit_precision 26 \
   --csoaa_ldf mc \
   --loss_function=logistic \
   --passes 10 \
   --cache_file $CACHE \
   --final_regressor $MODEL

rm $CACHE
